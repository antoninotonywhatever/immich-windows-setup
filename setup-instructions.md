This assumes you've got WSL and Docker Compose Configured. 

- Make a directory, cd into it, and grab the following
  - `wget -O docker-compose.yml https://github.com/immich-app/immich/releases/latest/download/docker-compose.yml`
  - `wget -O .env https://github.com/immich-app/immich/releases/latest/download/example.env`
  - `wget -O hwaccel.ml.yml https://github.com/immich-app/immich/releases/latest/download/hwaccel.ml.yml`
  - `wget -O hwaccel.transcoding.yml https://github.com/immich-app/immich/releases/latest/download/hwaccel.transcoding.yml`

Configure `env` and `docker-compose` according to these instructions. You can also find these files with configuration in this repo, but you shouldn't just copy those in, I provided them for reference. 

- Configuring `.env`
  - Set `UPLOAD_LOCATION` to where you want Immich to store any files you upload (You likely won't be doing a lot of this.
    - Do note though that this directory will store generated thumbnails and other data. It may grow to be tens of gigabytes in size, plan accordingly.
  - Define `EXTERNAL_PATH` with where you want Immich to search for files on your Windows device. It will search through all subdirectories at this path.
    - If you wish, define `EXTERNAL_PATH_2` (or 3, or 4, etc) with all the other locations you want it to search.
    - Eg, I have `EXTERNAL_PATH=D:\photo_migration` and `EXTERNAL_PATH_2=D:\lightroom_2023`
  - You'll need to do additional configuration later.    


- Configuring `docker-compose.yml`
  -  Uncomment and appropriately configure the `extends` sections for `hwaccel.transcoding.yml` and `hwaccel.ml.yml`
    - The files uploaded here are using Nvidia and CUDA, adjust accordingly for your hardware, or skip it entirely if you don't care
  - Add a path under `volumes` for `EXTERNAL_PATH`s, following what you did in the `.env` file
    - For example: `${EXTERNAL_PATH}:/usr/src/app/external` this is the location where an external directory will be stored on the immich server
    - You can add more, according to what's in your env
    - Eg `${EXTERNAL_PATH_2}:/usr/src/app/external`, you keep the server path the same.
    - I feel like there's a better way to do this.
  - Add a range to `ports` for `3003:3003`
    - This is necessary for some ML tasks. Before adding this, I'd have weird intermittent issues with facial detection not running

- Download AI models locally, this helps with some issues related to facial recognition
  - Make sure you're in the immich directory  
  - run `docker ps` and grab the `immich-machine-learning` id
  - Open a shell using `docker exec -it -u 0 container-id bash`
  - run `mkdir -p /cache/clip` and `/mkdir -p /cache/clip`
  - Create a temporary directory, and grab the following commands to clone models from hugging face and grant proper permissions
    - `git clone https://huggingface.co/immich-app/ViT-B-32__openai`
    - `git clone https://huggingface.co/immich-app/buffalo_l`
    - `docker ps #note immich-machine-learning id
    - `docker cp ViT-B-32__openai container-id:/cache/clip/`
    - `docker cp buffalo_l container-id:/cache/facial-recognition/`
    - `docker exec -u 0 container-id chmod -R 777 /cache`
  - Run `docker compose down` and `docker compose up -d`

Now you're ready to log in to the server! 
- run `docker compose up -d`
- Browse to http://localhost:2283 and configure an admin account

- Now, you'll add external libraries by browsing to http://localhost:2283/admin/library-management
  - Create a library, name it, and provide it with the path `/usr/src/app/external`
  - **This will begin indexing *all* of the `EXTERNAL_PATH`s you defined.**
    - All directories will be one external library on Immich
  - If you want multiple distinct external libraries in Immich, you'll need to define multiple valid paths on the server, eg `/usr/src/app/external_2`


- Configure concurrency for jobs
  - Depending on the resources available, you'll want to play around with concurrency limits under job settings here: http://localhost:2283/admin/system-settings?isOpen=job
  - Note that setting a super high limit (Eg, 2000) even on a very-well provisioned machine will be counter-productive and cause issues
  - I'd recommend experimenting by gradually increasing these from the default
- Run jobs at  http://localhost:2283/admin/jobs-status
  - In particular, run `External Libraries` to kick things off, and then make sure thumbnails, smart search, etc are generating.
  - Depending on the size of your library and your machine's resources, this can take a long time


From here, you should be good to go! I'd recommend monitoring logs occasionally to see if any problems occur. In particular, I've found ffmpeg has issues with the raw files generated by Leica cameras and for the "Live photos" `.mov`s generated by iPhones. 





Sources / What helped me along in configuration. Storing archives of these posts in `archive/` in case they go away.
This repo is partially a reference for me to be able to debug / disentangle this in the future when immich inevitably changes and I need to make updates. 

- [Immich docker compose docs](https://immich.app/docs/install/docker-compose/), [Immich Hardware Transcoding Docs](https://immich.app/docs/features/hardware-transcoding/),[ Immich Hardware-accelerated Machine Learning Docs](https://immich.app/docs/features/ml-hardware-acceleration/)
- [This Reddit Thread](https://www.reddit.com/r/immich/comments/1b5u6p2/comment/ktn7g2p/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) General config stuff, includes additional troubleshooting
- [This Reddit Thread](https://www.reddit.com/r/immich/comments/1i9un56/comment/m95fey1/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)
  - For opening a given port to make ML features work consistently
- [This Blog post](https://www.ephestione.it/immich-manually-download-machine-learning-ai-models/)
  - For troubleshooting ML/AI issues
